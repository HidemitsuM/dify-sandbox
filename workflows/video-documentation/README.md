# Video Documentation Workflow

動画を自動的にドキュメント化するDifyワークフローです。長いミーティングやカンファレンスの動画から、スナップショット、文字起こし、画像分析を自動的に行い、構造化されたドキュメントを生成します。

## 機能

- **スナップショット抽出**: 指定した間隔（デフォルト90秒）で動画からスナップショットを自動抽出
- **文字起こし**: Gemini 2.5を使用した高精度な音声文字起こし
- **マルチモーダル分析**: Gemini 2.5 Visionによる画像と文字起こしの統合分析
- **重要度スコアリング**: 各セグメントの重要度を自動評価（1-10スコア）
- **アクションアイテム抽出**: 会議からタスク、担当者、期限を自動抽出
- **スライドテキスト抽出**: 画像からOCRでテキストを抽出

## ワークフロー構成

```
Start（動画ファイル、パラメータ）
    ↓
Codeノード1：音声抽出 + スナップショット抽出
    ↓
LLMノード1：文字起こし（Gemini 2.5）
    ↓
Codeノード2：transcriptパース + スナップショット紐付け
    ↓
Codeノード3：バッチ分割（Gemini制限対応）
    ↓
Iterationノード：並列処理
    ↓
LLMノード2：画像+transcript分析（Gemini 2.5 Vision）
    ↓
Codeノード4：重要度スコア計算
    ↓
Codeノード5：結果収集
    ↓
LLMノード3：アクションアイテム抽出
    ↓
Template Transform：マークダウン出力生成
    ↓
End：最終ドキュメント
```

## 使用方法

### 1. Difyへのインポート

1. Difyのワークフロー画面で「DSLからインポート」を選択
2. `workflow.yml` ファイルをアップロード

### 2. APIキー設定

Difyの設定画面で以下のAPIキーを設定してください：

- **Google Gemini API**: Gemini 2.5 FlashのAPIキー

### 3. 実行方法

1. 動画ファイルをアップロード（MP4、MOV等）
2. パラメータを設定：
   - **スナップショット間隔**: デフォルト90秒（10-600秒）
   - **コンテキスト範囲**: デフォルト±30秒（10-120秒）
3. ワークフローを実行

## 入力

| パラメータ | 型 | 必須 | デフォルト | 説明 |
|-----------|----|----|-----------|------|
| video_file | file | ✓ | - | 動画ファイル（MP4、MOV等） |
| interval_seconds | number | - | 90 | スナップショット間隔（秒） |
| context_range | number | - | 30 | コンテキスト範囲（秒） |

## 出力

### 主要な出力

1. **ドキュメント**: マークダウン形式の構造化されたドキュメント
   - メタデータ
   - 目次
   - セグメント詳細
   - アクションアイテム一覧
   - 完全な文字起こし

2. **重要セグメント一覧**: 重要度の高いセグメントのみ抽出

3. **アクションアイテム**: タスク、担当者、期限、優先度

### セグメントデータ構造

```json
{
  "timestamp": 90.0,
  "summary": "セグメントの要約...",
  "slide_text": "スライドのテキスト...",
  "key_points": ["要点1", "要点2", "要点3"],
  "importance_score": 8.5,
  "normalized_importance": 0.85
}
```

## 制約

- **想定動画長**: 最大1時間程度
- **動画形式**: MP4、MOV等（ffmpegでサポートされる形式）
- **LLM**: Gemini 2.5 Flash（Google API）
- **画像処理**: 1バッチ最大16枚（Geminiの制限に対応）

## 技術仕様

### 依存ライブラリ（Codeノード内）

- `cv2` (OpenCV): 動画処理、スナップショット抽出
- `PIL` (Pillow): 画像処理、圧縮
- `subprocess`: ffmpegによる音声抽出
- `base64`: 画像エンコード
- `json`, `re`: データ処理

### 処理の流れ

1. **動画処理**:
   - ffmpegで音声トラックを抽出（WAV、16kHz、モラル）
   - OpenCVで指定間隔ごとにスナップショットをキャプチャ
   - 画像をJPEG品質85%、最大幅1280pxで圧縮
   - Base64エンコード

2. **文字起こし**:
   - Gemini 2.5に音声ファイルを直接投入
   - タイムスタンプ付きtranscriptを取得

3. **データ紐付け**:
   - transcriptをタイムスタンプでパース
   - 各スナップショットに前後±コンテキスト範囲のtranscriptを紐付け

4. **バッチ処理**:
   - セグメントを16個単位のバッチに分割
   - 並列処理で効率化

5. **画像分析**:
   - Gemini 2.5 Visionで各セグメントを分析
   - 要約、スライドテキスト、キーポイント、重要度スコアを抽出

6. **重要度スコアリング**:
   - スコアを正規化（0-1）
   - 閾値（0.7）を超えるセグメントを重要としてマーク

7. **アクションアイテム抽出**:
   - 全transcriptと重要セグメントの要約からタスクを抽出
   - 担当者、期限、優先度を特定

## 参考リソース

- [Dify公式ドキュメント](https://docs.dify.ai/)
- [Gemini 2.5 Documentation](https://ai.google.dev/gemini-api/docs)
- [OpenCV Video Processing](https://docs.opencv.org/4.x/dd/d43/tutorial_py_video_display.html)

## ライセンス

MIT

## 更新履歴

### v0.1.0 (2025-02-08)

- 初版リリース
- 基本的な動画処理、文字起こし、画像分析機能の実装
- 重要度スコアリング、アクションアイテム抽出機能の追加
